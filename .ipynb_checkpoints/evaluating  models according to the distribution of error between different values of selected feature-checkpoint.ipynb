{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a48330",
   "metadata": {},
   "source": [
    "# Import and watch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a3c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea77796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('tool touch detection.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc936b6",
   "metadata": {},
   "source": [
    "# Prepare and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'VALUE']\n",
    "\n",
    "y = df['VALUE']\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "number = preprocessing.LabelEncoder()\n",
    "X['S_I_CREATED_AT'] = number.fit_transform(X.S_I_CREATED_AT)\n",
    "X['DATE'] = number.fit_transform(X.DATE)\n",
    "X['GW_MAC'] = number.fit_transform(X.GW_MAC)\n",
    "X['GW_NAME'] = number.fit_transform(X.GW_NAME)\n",
    "X['TOOL_MAC'] = number.fit_transform(X.TOOL_MAC)\n",
    "X['TOOL_NAME'] = number.fit_transform(X.TOOL_NAME)       \n",
    "X['SESSION_INFO_ID'] = number.fit_transform(X.SESSION_INFO_ID)       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb79e4a",
   "metadata": {},
   "source": [
    "# Train and basically evaluate baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd14096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1253f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score: ',metrics.f1_score(y_test, y_pred),\n",
    "     'Accuracy Score: ',metrics.accuracy_score(y_test, y_pred),\n",
    "     'Precision Score: ',metrics.precision_score(y_test, y_pred),\n",
    "     'Recall Score: ',metrics.recall_score(y_test, y_pred))\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad44aeb",
   "metadata": {},
   "source": [
    "# Evaluating the model according to the distribution of error between different values of Session Info Id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_row_check = pd.DataFrame(columns = ['y pred', 'y'])\n",
    "prediction_row_check['y']=y_test\n",
    "prediction_row_check['y pred']=y_pred\n",
    "prediction_row_check['is prediction wrong'] = (prediction_row_check['y pred'] - prediction_row_check['y'])**2\n",
    "prediction_row_check['SESSION_INFO_ID']=X_test['SESSION_INFO_ID']\n",
    "prediction_row_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_session_check=pd.DataFrame(prediction_row_check.groupby('SESSION_INFO_ID')['is prediction wrong'].mean())\n",
    "prediction_session_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_session_check=pd.DataFrame(prediction_row_check.groupby('SESSION_INFO_ID')['is prediction wrong'].mean())\n",
    "prediction_session_check = prediction_session_check.reset_index()\n",
    "prediction_session_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.mean(prediction_row_check['is prediction wrong'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2808d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from statistics import mean\n",
    "prediction_session_check['abs difference from average'] = abs(prediction_session_check['is prediction wrong']-statistics.mean(prediction_row_check['is prediction wrong']))\n",
    "prediction_session_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815cc413",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (prediction_session_check['abs difference from average'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08130403",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (prediction_session_check['abs difference from average'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b136157",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_session_check[prediction_session_check['abs difference from average']>0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ef1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_session_check[prediction_session_check['abs difference from average']>0.2]['SESSION_INFO_ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_session_check[prediction_session_check['abs difference from average']>0.1]['SESSION_INFO_ID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3102a5",
   "metadata": {},
   "source": [
    "# Define the whole evaluation process as function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f7b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_model_tab = pd.DataFrame(columns = ['validation metric'])\n",
    "df_for_model_tab['validation metric'] = ('F1', 'Accuracy', 'Precision', 'Recall', 'max difference from error mean', 'mean difference from error mean', 'number of bigger than 0.2 differnece', 'number of bigger than 0.1 differnece')\n",
    "df_for_model_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_per_session(X, y, model, model_name):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) \n",
    "\n",
    "    \n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    prediction_row_check = pd.DataFrame(columns = ['y pred', 'y'])\n",
    "    prediction_row_check['y']=y_test\n",
    "    prediction_row_check['y pred']=y_pred\n",
    "    prediction_row_check['SESSION_INFO_ID']=X_test['SESSION_INFO_ID']\n",
    "    prediction_row_check['is prediction wrong'] = (prediction_row_check['y pred'] - prediction_row_check['y'])**2\n",
    "    \n",
    "    prediction_session_check=pd.DataFrame(prediction_row_check.groupby('SESSION_INFO_ID')['is prediction wrong'].mean())\n",
    "    prediction_session_check = prediction_session_check.reset_index()\n",
    "    \n",
    "    prediction_session_check['abs difference from average'] = abs(prediction_session_check['is prediction wrong']-statistics.mean(prediction_row_check['is prediction wrong']))\n",
    "    \n",
    "    df_for_model_tab[model_name] = metrics.f1_score(y_test, y_pred), metrics.accuracy_score(y_test, y_pred), metrics.precision_score(y_test, y_pred), metrics.recall_score(y_test, y_pred), prediction_session_check['abs difference from average'].max(), prediction_session_check['abs difference from average'].mean(), prediction_session_check[prediction_session_check['abs difference from average']>0.2]['SESSION_INFO_ID'].count(), prediction_session_check[prediction_session_check['abs difference from average']>0.1]['SESSION_INFO_ID'].count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854f095",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_per_session(X, y, RandomForestClassifier(max_depth=2, random_state=0), 'Random Forest')\n",
    "df_for_model_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ffd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_per_session(X, y, DecisionTreeClassifier(), 'Decision Tree')\n",
    "df_for_model_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_per_session(X, y, AdaBoostClassifier(), 'Ada Boost')\n",
    "df_for_model_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295b164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
